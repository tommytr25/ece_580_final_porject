{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "882c45db-add5-497e-a7a7-a762c6104307",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "100b1a50-ee4f-4edc-a3f3-3dd25278af0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "019b8d52-f572-4380-8119-8f33ad5cd6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model architecture\n",
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding='same'),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding='same'),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(UNet, self).__init__()\n",
    "        # Encoder\n",
    "        self.conv1 = DoubleConv(1, 32)\n",
    "        self.conv2 = DoubleConv(32, 64)\n",
    "        self.conv3 = DoubleConv(64, 128)\n",
    "        \n",
    "        # Decoder\n",
    "        self.up_conv2 = DoubleConv(192, 64)  # 128 + 64 channels\n",
    "        self.up_conv1 = DoubleConv(96, 32)   # 64 + 32 channels\n",
    "        \n",
    "        # Final convolution\n",
    "        self.final_conv = nn.Conv2d(32, 3, kernel_size=1)\n",
    "        \n",
    "        # Pooling and upsampling\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "        self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        conv1 = self.conv1(x)\n",
    "        x = self.pool(conv1)\n",
    "        \n",
    "        conv2 = self.conv2(x)\n",
    "        x = self.pool(conv2)\n",
    "        \n",
    "        # Bridge\n",
    "        x = self.conv3(x)\n",
    "        \n",
    "        # Decoder\n",
    "        x = self.up(x)\n",
    "        x = torch.cat([x, conv2], dim=1)\n",
    "        x = self.up_conv2(x)\n",
    "        \n",
    "        x = self.up(x)\n",
    "        x = torch.cat([x, conv1], dim=1)\n",
    "        x = self.up_conv1(x)\n",
    "        \n",
    "        # Final convolution\n",
    "        x = self.final_conv(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b5ef799-7251-4a29-bef8-79e27fcbcf0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_psnr(img1, img2):\n",
    "    \"\"\"Calculate PSNR between two images.\"\"\"\n",
    "    mse = np.mean((img1 - img2) ** 2)\n",
    "    if mse == 0:\n",
    "        return float('inf')\n",
    "    return 20 * np.log10(1.0 / np.sqrt(mse))\n",
    "    \n",
    "def calculate_cpsnr(img1, img2):\n",
    "    \"\"\"Calculate Color PSNR (average of R,G,B channels) and individual channel PSNRs.\"\"\"\n",
    "    psnr_r = calculate_psnr(img1[:,:,0], img2[:,:,0])\n",
    "    psnr_g = calculate_psnr(img1[:,:,1], img2[:,:,1])\n",
    "    psnr_b = calculate_psnr(img1[:,:,2], img2[:,:,2])\n",
    "    return psnr_r, psnr_g, psnr_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f63a05c3-0654-4c92-a006-5430bfe6d323",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2302043/4150807392.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load('best_unet_model.pth')\n"
     ]
    }
   ],
   "source": [
    "# Initialize model and load weights\n",
    "model = UNet().to(device)\n",
    "checkpoint = torch.load('best_unet_model.pth')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()\n",
    "\n",
    "# Dataset path and test split file\n",
    "dataset_path = 'dataset/MSR-Demosaicing/MSR-Demosaicing/Dataset_LINEAR_without_noise/bayer_panasonic'\n",
    "test_split_file = os.path.join(dataset_path, 'test.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d53acb6a-e3be-4910-adf2-9dffb833fd1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Calculating PSNR for all test images...\n",
      "Processing image 200/200\n",
      "PSNR calculation complete!\n",
      "\n",
      "Test Set Results:\n",
      "R channel - Mean: 37.01 dB, Std: 4.45 dB\n",
      "G channel - Mean: 41.59 dB, Std: 4.01 dB\n",
      "B channel - Mean: 37.97 dB, Std: 4.37 dB\n",
      "CPSNR     - Mean: 38.86 dB, Std: 4.72 dB\n"
     ]
    }
   ],
   "source": [
    "# Dataset path and test split file\n",
    "dataset_path = 'dataset/MSR-Demosaicing/MSR-Demosaicing/Dataset_LINEAR_without_noise/bayer_panasonic'\n",
    "test_split_file = os.path.join(dataset_path, 'test.txt')\n",
    "\n",
    "# Read all test images\n",
    "with open(test_split_file, 'r') as f:\n",
    "    test_images = [line.strip() + '.png' for line in f.readlines()]\n",
    "\n",
    "# Calculate PSNR for all test images\n",
    "r_psnr_values = []\n",
    "g_psnr_values = []\n",
    "b_psnr_values = []\n",
    "print(\"\\nCalculating PSNR for all test images...\")\n",
    "\n",
    "for i, img_file in enumerate(test_images):\n",
    "    print(f\"Processing image {i+1}/{len(test_images)}\", end='\\r')\n",
    "    \n",
    "    # Load ground truth image\n",
    "    gt_path = os.path.join(dataset_path, 'groundtruth', img_file)\n",
    "    gt_img = cv2.imread(gt_path)\n",
    "    gt_img = cv2.cvtColor(gt_img, cv2.COLOR_BGR2RGB)\n",
    "    gt_img = gt_img.astype(np.float32) / 255.0\n",
    "    \n",
    "    # Load and normalize Bayer image\n",
    "    input_path = os.path.join(dataset_path, 'input', img_file)\n",
    "    bayer_img = cv2.imread(input_path, cv2.IMREAD_UNCHANGED)\n",
    "    bayer_img = bayer_img.astype(np.float32) / 65535.0\n",
    "    \n",
    "    # Process with model\n",
    "    with torch.no_grad():\n",
    "        input_tensor = torch.from_numpy(bayer_img).float().unsqueeze(0).unsqueeze(0).to(device)\n",
    "        output = model(input_tensor)\n",
    "        output_img = output[0].cpu().numpy().transpose(1, 2, 0)\n",
    "        output_img = np.clip(output_img, 0, 1)\n",
    "    \n",
    "    # Calculate PSNR for each channel\n",
    "    r_psnr, g_psnr, b_psnr = calculate_cpsnr(gt_img, output_img)\n",
    "    r_psnr_values.append(r_psnr)\n",
    "    g_psnr_values.append(g_psnr)\n",
    "    b_psnr_values.append(b_psnr)\n",
    "\n",
    "print(\"\\nPSNR calculation complete!\")\n",
    "\n",
    "# Calculate statistics\n",
    "mean_r_psnr = np.mean(r_psnr_values)\n",
    "mean_g_psnr = np.mean(g_psnr_values)\n",
    "mean_b_psnr = np.mean(b_psnr_values)\n",
    "mean_cpsnr = (mean_r_psnr + mean_g_psnr + mean_b_psnr) / 3.0\n",
    "\n",
    "std_r_psnr = np.std(r_psnr_values)\n",
    "std_g_psnr = np.std(g_psnr_values)\n",
    "std_b_psnr = np.std(b_psnr_values)\n",
    "std_cpsnr = np.std([r_psnr_values, g_psnr_values, b_psnr_values])\n",
    "\n",
    "print(f\"\\nTest Set Results:\")\n",
    "print(f\"R channel - Mean: {mean_r_psnr:.2f} dB, Std: {std_r_psnr:.2f} dB\")\n",
    "print(f\"G channel - Mean: {mean_g_psnr:.2f} dB, Std: {std_g_psnr:.2f} dB\")\n",
    "print(f\"B channel - Mean: {mean_b_psnr:.2f} dB, Std: {std_b_psnr:.2f} dB\")\n",
    "print(f\"CPSNR     - Mean: {mean_cpsnr:.2f} dB, Std: {std_cpsnr:.2f} dB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50ea7c89-be89-4c6a-b307-a9a07fa2b5aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Output images saved in 'results_unet' directory.\n"
     ]
    }
   ],
   "source": [
    "# Save first 4 results\n",
    "os.makedirs('results_unet', exist_ok=True)\n",
    "for i in range(4):\n",
    "    img_file = test_images[i]\n",
    "    \n",
    "    # Load and normalize Bayer image\n",
    "    input_path = os.path.join(dataset_path, 'input', img_file)\n",
    "    bayer_img = cv2.imread(input_path, cv2.IMREAD_UNCHANGED)\n",
    "    bayer_img = bayer_img.astype(np.float32) / 65535.0\n",
    "    \n",
    "    # Process with model\n",
    "    with torch.no_grad():\n",
    "        input_tensor = torch.from_numpy(bayer_img).float().unsqueeze(0).unsqueeze(0).to(device)\n",
    "        output = model(input_tensor)\n",
    "        output_img = output[0].cpu().numpy().transpose(1, 2, 0)\n",
    "        output_img = np.clip(output_img, 0, 1)\n",
    "    \n",
    "    # Save output image\n",
    "    output_img = (output_img * 255).astype(np.uint8)\n",
    "    output_img = cv2.cvtColor(output_img, cv2.COLOR_RGB2BGR)\n",
    "    cv2.imwrite(f'results_unet/{img_file}', output_img)\n",
    "\n",
    "print(\"\\nOutput images saved in 'results_unet' directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1018d4b3-a6aa-403d-ba50-38184a855541",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
