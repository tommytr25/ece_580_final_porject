{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c94fe5f-84cf-4506-a9c6-9c663bf6cfe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "619d7504-c530-4fb3-b874-62b9fc2f5206",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DMCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DMCNN, self).__init__()\n",
    "        self.feature_extraction = nn.Conv2d(3, 128, kernel_size=9, padding=4)\n",
    "        self.relu1 = nn.ReLU(inplace=True)\n",
    "        self.nonlinear_mapping = nn.Conv2d(128, 64, kernel_size=1)\n",
    "        self.relu2 = nn.ReLU(inplace=True)\n",
    "        self.reconstruction = nn.Conv2d(64, 3, kernel_size=5, padding=2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        features = self.relu1(self.feature_extraction(x))\n",
    "        mapped = self.relu2(self.nonlinear_mapping(features))\n",
    "        out = self.reconstruction(mapped)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f00f1e61-718b-4077-b652-154b34c3ad58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_psnr(img1, img2, max_val=1.0):\n",
    "    \"\"\"Calculate PSNR between two images\"\"\"\n",
    "    mse = np.mean((img1 - img2) ** 2)\n",
    "    return 20 * np.log10(max_val / np.sqrt(mse))\n",
    "\n",
    "def calculate_cpsnr(img1, img2):\n",
    "    \"\"\"Calculate Color PSNR (average of R,G,B channels) and individual channel PSNRs.\"\"\"\n",
    "    psnr_r = calculate_psnr(img1[:,:,0], img2[:,:,0])\n",
    "    psnr_g = calculate_psnr(img1[:,:,1], img2[:,:,1])\n",
    "    psnr_b = calculate_psnr(img1[:,:,2], img2[:,:,2])\n",
    "    return psnr_r, psnr_g, psnr_b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6878a7a8-ea6e-450b-ae53-acdd6d60e85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cfa_channels(bayer_img):\n",
    "    \"\"\"Convert single-channel Bayer image to 3-channel representation.\"\"\"\n",
    "    H, W = bayer_img.shape\n",
    "    cfa = np.zeros((H, W, 3), dtype=bayer_img.dtype)\n",
    "    \n",
    "    # RGGB pattern\n",
    "    cfa[0::2, 0::2, 0] = bayer_img[0::2, 0::2]  # R\n",
    "    cfa[0::2, 1::2, 1] = bayer_img[0::2, 1::2]  # G\n",
    "    cfa[1::2, 0::2, 1] = bayer_img[1::2, 0::2]  # G\n",
    "    cfa[1::2, 1::2, 2] = bayer_img[1::2, 1::2]  # B\n",
    "    \n",
    "    return cfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ae2763e-d3f1-4454-9c9f-cb02005a2b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(model, bayer_img, patch_size=33, overlap=6):\n",
    "    \"\"\"Process image using patch-based approach\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    h, w = bayer_img.shape\n",
    "    output = np.zeros((h, w, 3), dtype=np.float32)\n",
    "    weights = np.zeros((h, w, 3), dtype=np.float32)\n",
    "    \n",
    "    initial_rgb = np.stack([bayer_img, bayer_img, bayer_img], axis=-1)  # Create 3 identical channels\n",
    "    \n",
    "    stride = patch_size - overlap\n",
    "    target_size = 33  # Output size after convolutions\n",
    "    margin = (patch_size - target_size) // 2\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for y in range(0, h - patch_size + 1, stride):\n",
    "            for x in range(0, w - patch_size + 1, stride):\n",
    "                # Extract patch from initial RGB estimate\n",
    "                patch = initial_rgb[y:y+patch_size, x:x+patch_size]\n",
    "                \n",
    "                # Convert to tensor\n",
    "                patch_tensor = torch.from_numpy(patch).float().permute(2, 0, 1).unsqueeze(0)\n",
    "                patch_tensor = patch_tensor.to(device)\n",
    "                \n",
    "                # Process patch\n",
    "                output_patch = model(patch_tensor)\n",
    "                output_patch = output_patch.squeeze().cpu().numpy()\n",
    "                output_patch = output_patch.transpose(1, 2, 0)\n",
    "                \n",
    "                # Calculate output position\n",
    "                out_y = y + margin\n",
    "                out_x = x + margin\n",
    "                \n",
    "                # Create weight mask (gaussian falloff)\n",
    "                weight_mask = np.ones((target_size, target_size, 1))\n",
    "                if overlap > 0:\n",
    "                    for i in range(overlap):\n",
    "                        weight = np.exp(-((i - overlap/2)**2) / (2*(overlap/4)**2))\n",
    "                        weight_mask[i, :] *= weight\n",
    "                        weight_mask[-(i+1), :] *= weight\n",
    "                        weight_mask[:, i] *= weight\n",
    "                        weight_mask[:, -(i+1)] *= weight\n",
    "                \n",
    "                # Add to output\n",
    "                output[out_y:out_y+target_size, out_x:out_x+target_size] += output_patch * weight_mask\n",
    "                weights[out_y:out_y+target_size, out_x:out_x+target_size] += weight_mask\n",
    "    \n",
    "    # Handle borders\n",
    "    mask = (weights != 0)\n",
    "    output[mask] /= weights[mask]\n",
    "    output[~mask] = initial_rgb[~mask]\n",
    "    \n",
    "    return output, initial_rgb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4bd18551-01e7-4abd-910d-0530f2912ef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing 24 images from Kodak dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2290878/1283937183.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load('../best_demosaic_model.pth', map_location=device)\n"
     ]
    }
   ],
   "source": [
    "# Initialize model and load weights\n",
    "model = DMCNN().to(device)\n",
    "checkpoint = torch.load('../best_demosaic_model.pth', map_location=device)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()\n",
    "\n",
    "# Set up paths\n",
    "input_dir = '../dataset/kodak/input'\n",
    "gt_dir = '../dataset/kodak/groundtruth'\n",
    "\n",
    "# Get list of images\n",
    "input_images = sorted([f for f in os.listdir(input_dir) if f.endswith('.png')])\n",
    "total_images = len(input_images)\n",
    "\n",
    "print(f\"\\nProcessing {total_images} images from Kodak dataset...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9cf429aa-33e1-49f7-a08e-9ac70ad39dc4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Calculating PSNR for all test images...\n",
      "Processing image 1/24: kodim01.png\n",
      "Processing image 2/24: kodim02.png\n",
      "Processing image 3/24: kodim03.png\n",
      "Processing image 4/24: kodim04.png\n",
      "Processing image 5/24: kodim05.png\n",
      "Processing image 6/24: kodim06.png\n",
      "Processing image 7/24: kodim07.png\n",
      "Processing image 8/24: kodim08.png\n",
      "Processing image 9/24: kodim09.png\n",
      "Processing image 10/24: kodim10.png\n",
      "Processing image 11/24: kodim11.png\n",
      "Processing image 12/24: kodim12.png\n",
      "Processing image 13/24: kodim13.png\n",
      "Processing image 14/24: kodim14.png\n",
      "Processing image 15/24: kodim15.png\n",
      "Processing image 16/24: kodim16.png\n",
      "Processing image 17/24: kodim17.png\n",
      "Processing image 18/24: kodim18.png\n",
      "Processing image 19/24: kodim19.png\n",
      "Processing image 20/24: kodim20.png\n",
      "Processing image 21/24: kodim21.png\n",
      "Processing image 22/24: kodim22.png\n",
      "Processing image 23/24: kodim23.png\n",
      "Processing image 24/24: kodim24.png\n",
      "\n",
      "PSNR calculation complete!\n"
     ]
    }
   ],
   "source": [
    "# Calculate PSNR for all test images\n",
    "r_psnr_values = []\n",
    "g_psnr_values = []\n",
    "b_psnr_values = []\n",
    "print(\"\\nCalculating PSNR for all test images...\")\n",
    "\n",
    "# Making new dir to save results\n",
    "os.makedirs('result_kodak_dmcnn', exist_ok=True)\n",
    "\n",
    "# Process each image\n",
    "results = []\n",
    "for idx, img_file in enumerate(input_images):\n",
    "    print(f\"Processing image {idx+1}/{total_images}: {img_file}\")\n",
    "    \n",
    "    # Load input image\n",
    "    input_path = os.path.join(input_dir, img_file)\n",
    "    input_img = cv2.imread(input_path, cv2.IMREAD_UNCHANGED)\n",
    "    input_img = input_img.astype(np.float32) / 255.0\n",
    "    \n",
    "    # Load ground truth image\n",
    "    gt_path = os.path.join(gt_dir, img_file)\n",
    "    gt_img = cv2.imread(gt_path)\n",
    "    gt_img = cv2.cvtColor(gt_img, cv2.COLOR_BGR2RGB)\n",
    "    gt_img = gt_img.astype(np.float32) / 255.0\n",
    "\n",
    "    # Convert to 3-channel input\n",
    "    input_3ch = create_cfa_channels(input_img)\n",
    "    \n",
    "   # Process with model\n",
    "    with torch.no_grad():\n",
    "        input_tensor = torch.from_numpy(input_3ch).float().permute(2, 0, 1).unsqueeze(0).to(device)\n",
    "        output = model(input_tensor)\n",
    "        output_img = output[0].cpu().numpy().transpose(1, 2, 0)\n",
    "        output_img = np.clip(output_img, 0, 1)\n",
    "        \n",
    "    \n",
    "    # Calculate PSNR for each channel\n",
    "    r_psnr, g_psnr, b_psnr = calculate_cpsnr(gt_img, output_img)\n",
    "    r_psnr_values.append(r_psnr)\n",
    "    g_psnr_values.append(g_psnr)\n",
    "    b_psnr_values.append(b_psnr)\n",
    "\n",
    "    # Convert to uint8 and save\n",
    "    output_img = (output_img * 255).astype(np.uint8)\n",
    "    output_img = cv2.cvtColor(output_img, cv2.COLOR_RGB2BGR)\n",
    "    cv2.imwrite(f'result_kodak_dmcnn/{img_file}', output_img)\n",
    "\n",
    "print(\"\\nPSNR calculation complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec1009a6-10db-4fed-b8b4-b419e1481b93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Set Results:\n",
      "R channel - Mean: 36.77 dB, Std: 2.17 dB\n",
      "G channel - Mean: 39.86 dB, Std: 2.03 dB\n",
      "B channel - Mean: 36.37 dB, Std: 2.03 dB\n",
      "CPSNR     - Mean: 37.67 dB, Std: 2.60 dB\n"
     ]
    }
   ],
   "source": [
    "# Calculate statistics\n",
    "mean_r_psnr = np.mean(r_psnr_values)\n",
    "mean_g_psnr = np.mean(g_psnr_values)\n",
    "mean_b_psnr = np.mean(b_psnr_values)\n",
    "mean_cpsnr = (mean_r_psnr + mean_g_psnr + mean_b_psnr) / 3.0\n",
    "\n",
    "std_r_psnr = np.std(r_psnr_values)\n",
    "std_g_psnr = np.std(g_psnr_values)\n",
    "std_b_psnr = np.std(b_psnr_values)\n",
    "std_cpsnr = np.std([r_psnr_values, g_psnr_values, b_psnr_values])\n",
    "\n",
    "print(f\"\\nTest Set Results:\")\n",
    "print(f\"R channel - Mean: {mean_r_psnr:.2f} dB, Std: {std_r_psnr:.2f} dB\")\n",
    "print(f\"G channel - Mean: {mean_g_psnr:.2f} dB, Std: {std_g_psnr:.2f} dB\")\n",
    "print(f\"B channel - Mean: {mean_b_psnr:.2f} dB, Std: {std_b_psnr:.2f} dB\")\n",
    "print(f\"CPSNR     - Mean: {mean_cpsnr:.2f} dB, Std: {std_cpsnr:.2f} dB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905f99b9-2291-4536-8c67-82a0791c55bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1f8c5b-a536-4acf-a62d-4807c16e9372",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da17b32d-17c4-43bb-9bbd-1323817a7300",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
