{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4427b7c-d98b-4b6f-ba33-de2799eccf87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2462849/637254476.py:102: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load('../best_demosaic_model.pth', map_location=device)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for DMCNN:\n\tMissing key(s) in state_dict: \"feature_layer.0.weight\", \"feature_layer.0.bias\", \"mapping_layer.0.weight\", \"mapping_layer.0.bias\", \"reconstruction_layer.0.weight\", \"reconstruction_layer.0.bias\". \n\tUnexpected key(s) in state_dict: \"feature_extraction.weight\", \"feature_extraction.bias\", \"nonlinear_mapping.weight\", \"nonlinear_mapping.bias\", \"reconstruction.weight\", \"reconstruction.bias\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 103\u001b[0m\n\u001b[1;32m    101\u001b[0m model \u001b[38;5;241m=\u001b[39m DMCNN()\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    102\u001b[0m checkpoint \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../best_demosaic_model.pth\u001b[39m\u001b[38;5;124m'\u001b[39m, map_location\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[0;32m--> 103\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodel_state_dict\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    104\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m    106\u001b[0m \u001b[38;5;66;03m# Set up paths\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/ece580/lib/python3.12/site-packages/torch/nn/modules/module.py:2215\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2210\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[1;32m   2211\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2212\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)))\n\u001b[1;32m   2214\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2215\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2216\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   2217\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for DMCNN:\n\tMissing key(s) in state_dict: \"feature_layer.0.weight\", \"feature_layer.0.bias\", \"mapping_layer.0.weight\", \"mapping_layer.0.bias\", \"reconstruction_layer.0.weight\", \"reconstruction_layer.0.bias\". \n\tUnexpected key(s) in state_dict: \"feature_extraction.weight\", \"feature_extraction.bias\", \"nonlinear_mapping.weight\", \"nonlinear_mapping.bias\", \"reconstruction.weight\", \"reconstruction.bias\". "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# DMCNN model definition (original, without padding)\n",
    "class DMCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DMCNN, self).__init__()\n",
    "        \n",
    "        self.feature_layer = nn.Sequential(\n",
    "            nn.Conv2d(3, 128, kernel_size=9, padding=0),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.mapping_layer = nn.Sequential(\n",
    "            nn.Conv2d(128, 64, kernel_size=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.reconstruction_layer = nn.Sequential(\n",
    "            nn.Conv2d(64, 3, kernel_size=5),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.feature_layer(x)\n",
    "        out = self.mapping_layer(out)\n",
    "        out = self.reconstruction_layer(out)\n",
    "        return out\n",
    "\n",
    "def calculate_psnr(img1, img2, max_val=1.0):\n",
    "    \"\"\"Calculate PSNR between two images\"\"\"\n",
    "    mse = np.mean((img1 - img2) ** 2)\n",
    "    return 20 * np.log10(max_val / np.sqrt(mse))\n",
    "\n",
    "def process_image(model, bayer_img, patch_size=33, overlap=6):\n",
    "    \"\"\"Process image using patch-based approach\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    h, w = bayer_img.shape\n",
    "    output = np.zeros((h, w, 3), dtype=np.float32)\n",
    "    weights = np.zeros((h, w, 3), dtype=np.float32)\n",
    "    \n",
    "    # Initial RGB estimate for full image\n",
    "    bayer_uint8 = (bayer_img * 255).astype(np.uint8)\n",
    "    initial_rgb = cv2.cvtColor(bayer_uint8, cv2.COLOR_BAYER_BG2RGB_EA)\n",
    "    initial_rgb = initial_rgb.astype(np.float32) / 255.0\n",
    "    \n",
    "    stride = patch_size - overlap\n",
    "    target_size = 21  # Output size after convolutions\n",
    "    margin = (patch_size - target_size) // 2\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for y in range(0, h - patch_size + 1, stride):\n",
    "            for x in range(0, w - patch_size + 1, stride):\n",
    "                # Extract patch from initial RGB estimate\n",
    "                patch = initial_rgb[y:y+patch_size, x:x+patch_size]\n",
    "                \n",
    "                # Convert to tensor\n",
    "                patch_tensor = torch.from_numpy(patch).float().permute(2, 0, 1).unsqueeze(0)\n",
    "                patch_tensor = patch_tensor.to(device)\n",
    "                \n",
    "                # Process patch\n",
    "                output_patch = model(patch_tensor)\n",
    "                output_patch = output_patch.squeeze().cpu().numpy()\n",
    "                output_patch = output_patch.transpose(1, 2, 0)\n",
    "                \n",
    "                # Calculate output position\n",
    "                out_y = y + margin\n",
    "                out_x = x + margin\n",
    "                \n",
    "                # Create weight mask (gaussian falloff)\n",
    "                weight_mask = np.ones((target_size, target_size, 1))\n",
    "                if overlap > 0:\n",
    "                    for i in range(overlap):\n",
    "                        weight = np.exp(-((i - overlap/2)**2) / (2*(overlap/4)**2))\n",
    "                        weight_mask[i, :] *= weight\n",
    "                        weight_mask[-(i+1), :] *= weight\n",
    "                        weight_mask[:, i] *= weight\n",
    "                        weight_mask[:, -(i+1)] *= weight\n",
    "                \n",
    "                # Add to output\n",
    "                output[out_y:out_y+target_size, out_x:out_x+target_size] += output_patch * weight_mask\n",
    "                weights[out_y:out_y+target_size, out_x:out_x+target_size] += weight_mask\n",
    "    \n",
    "    # Handle borders\n",
    "    mask = (weights != 0)\n",
    "    output[mask] /= weights[mask]\n",
    "    output[~mask] = initial_rgb[~mask]\n",
    "    \n",
    "    return output, initial_rgb\n",
    "\n",
    "# Initialize model and load weights\n",
    "model = DMCNN().to(device)\n",
    "checkpoint = torch.load('../best_demosaic_model.pth', map_location=device)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()\n",
    "\n",
    "# Set up paths\n",
    "input_dir = '../dataset/kodak/input'\n",
    "gt_dir = '../dataset/kodak/groundtruth'\n",
    "\n",
    "# Get list of images\n",
    "input_images = sorted([f for f in os.listdir(input_dir) if f.endswith('.png')])\n",
    "total_images = len(input_images)\n",
    "\n",
    "print(f\"\\nProcessing {total_images} images from Kodak dataset...\")\n",
    "\n",
    "# Process each image\n",
    "results = []\n",
    "for idx, img_file in enumerate(input_images):\n",
    "    print(f\"Processing image {idx+1}/{total_images}: {img_file}\")\n",
    "    \n",
    "    # Load input image\n",
    "    input_path = os.path.join(input_dir, img_file)\n",
    "    input_img = cv2.imread(input_path, cv2.IMREAD_UNCHANGED)\n",
    "    input_img = input_img.astype(np.float32) / 255.0\n",
    "    \n",
    "    # Load ground truth image\n",
    "    gt_path = os.path.join(gt_dir, img_file)\n",
    "    gt_img = cv2.imread(gt_path)\n",
    "    gt_img = cv2.cvtColor(gt_img, cv2.COLOR_BGR2RGB)\n",
    "    gt_img = gt_img.astype(np.float32) / 255.0\n",
    "    \n",
    "    # Process with patches\n",
    "    output_img, initial_rgb = process_image(model, input_img)\n",
    "    \n",
    "    # Calculate PSNR\n",
    "    psnr_dmcnn = calculate_psnr(gt_img, output_img)\n",
    "    psnr_initial = calculate_psnr(gt_img, initial_rgb)\n",
    "    \n",
    "    results.append({\n",
    "        'image': img_file,\n",
    "        'dmcnn_psnr': psnr_dmcnn,\n",
    "        'initial_psnr': psnr_initial\n",
    "    })\n",
    "    \n",
    "    # Print current image results\n",
    "    print(f\"DMCNN PSNR: {psnr_dmcnn:.2f} dB\")\n",
    "    print(f\"Initial PSNR: {psnr_initial:.2f} dB\")\n",
    "    print(f\"Improvement: {psnr_dmcnn - psnr_initial:.2f} dB\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Visualize results\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    plt.subplot(131)\n",
    "    plt.imshow(initial_rgb)\n",
    "    plt.title(f'Bilinear\\nPSNR: {psnr_initial:.2f} dB')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(132)\n",
    "    plt.imshow(np.clip(output_img, 0, 1))\n",
    "    plt.title(f'DMCNN\\nPSNR: {psnr_dmcnn:.2f} dB')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(133)\n",
    "    plt.imshow(gt_img)\n",
    "    plt.title('Ground Truth')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.suptitle(f'Image: {img_file}')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Print final results\n",
    "print(\"\\nResults Summary:\")\n",
    "print(\"-\" * 50)\n",
    "avg_dmcnn_psnr = np.mean([r['dmcnn_psnr'] for r in results])\n",
    "avg_initial_psnr = np.mean([r['initial_psnr'] for r in results])\n",
    "print(f\"Average DMCNN PSNR: {avg_dmcnn_psnr:.2f} dB\")\n",
    "print(f\"Average Initial PSNR: {avg_initial_psnr:.2f} dB\")\n",
    "print(f\"Average Improvement: {avg_dmcnn_psnr - avg_initial_psnr:.2f} dB\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
